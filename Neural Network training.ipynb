{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5,0.5),\n",
    "                                                   (0.5, 0.5, 0.5))\n",
    "                               ])\n",
    "#download the training set data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into trainloader and we can make that an iterator with iter(trainloader) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size=64 -- number of images in one iteration.\n",
    "We can see that the images from this batch is a tensor with size (64,1,28,28)\n",
    "64 images per batch\n",
    "1 color channel\n",
    "28 x 28 pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x123b901d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: \n",
    "Flatten the batch of images images. Then build a multi-layer network with 784 input units, 256 hidden units, and 10 output units using random tensors for the weights and biases. For now, use a sigmoid activation for the hidden layer. Leave the output layer without an activation, we'll add one that gives us a probability distribution next\n",
    "\n",
    "inputs = 784 (x)\n",
    "\n",
    "\n",
    "hidden units = 256 (h)\n",
    "\n",
    "\n",
    "output = 10 (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "def activation(x):\n",
    "    #sigmoid activation\n",
    "    return 1/(1 + torch.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the input images\n",
    "inputs = images.view(images.shape[0],-1)\n",
    "#inputs\n",
    "\n",
    "#create parameters\n",
    "w1 = torch.randn(784,256)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256,10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "#print(w1,b1,w2,b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = activation(torch.mm(inputs,w1) + b1)\n",
    "out = torch.mm(h,w2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4.4271, -16.0467,  -8.7036,  10.1076,   2.2282,  15.8181,  -5.6912,\n",
       "           3.6021, -18.6088,  -0.1671],\n",
       "        [ -3.4397,  -6.5920,   0.7185,   2.6913,   9.5039,   9.6732,  -3.4791,\n",
       "          -0.9720, -24.3249,   5.8168],\n",
       "        [  4.5698, -10.6528, -13.2498,   0.7073,  10.2393,   6.0818,  -5.1719,\n",
       "          -5.6147, -23.2898,   1.0527],\n",
       "        [ -0.3484,  -0.7832,  -1.2952,  -3.0962,  19.4188,   3.4055,  -4.8005,\n",
       "           8.9173, -18.6277,  -4.1022],\n",
       "        [  4.1136, -16.3325,  -0.5591,   3.5980,   4.3833,   4.7440, -19.1738,\n",
       "          -6.4344, -25.1976,  -2.2279],\n",
       "        [ -1.1208,   1.4825,  -2.9020,   5.9505,  13.4303,   7.4345, -18.0076,\n",
       "          -8.3061, -18.2107,  -1.6301],\n",
       "        [ -0.7744, -20.6183, -14.1120,   7.1365,   3.9934,   8.9876,  -2.1790,\n",
       "           1.6805, -15.8376,  -7.8509],\n",
       "        [ -8.4008, -10.6233,  -4.2186,   1.5524,  17.0662,  -1.7018,  -9.2277,\n",
       "          -7.4391, -16.2941,  -0.3895],\n",
       "        [  4.8238, -10.1115, -12.5755,   9.6713,   1.0053,   5.7216, -18.8797,\n",
       "           0.5522, -16.2368,  -7.8482],\n",
       "        [  3.4462, -15.4777,   2.7708,   3.2298,   8.6006,   9.3726,  -7.7465,\n",
       "          -7.0431, -14.5132,  -3.9354],\n",
       "        [ -4.1912, -14.1529,   5.9956,   3.5791,   6.4046,   9.7769, -18.3694,\n",
       "          -7.2211, -17.4439, -12.7764],\n",
       "        [ -2.7526, -17.2670,   1.8504,   4.5966,   8.8798,   6.3664, -14.1323,\n",
       "          -3.5467,  -5.6713,   0.1288],\n",
       "        [  2.8588, -14.2738, -15.2149,   6.4458,   5.6200,   4.2945,  -9.2695,\n",
       "          -0.1319, -12.4287,  -4.6550],\n",
       "        [ -9.3730, -20.6231,  -8.7979,   0.7025,  18.4555,  15.7754,   5.5963,\n",
       "           2.4864, -17.2053,  -7.4418],\n",
       "        [ -8.2189, -14.8908,  -3.7043,   6.3946,  16.2405,  20.7653,  -2.3377,\n",
       "          -2.5619,  -9.2030,   2.9124],\n",
       "        [  5.5159, -15.3542,  -4.4452,   7.7909,  13.4766,  14.5845,  -5.3966,\n",
       "           0.3775,  -6.6695,   4.1563],\n",
       "        [ -6.5561, -14.4628,  -9.2833,   1.2897,   2.2462,   9.8307,   0.5138,\n",
       "           2.0452,  -6.7399,  -1.4681],\n",
       "        [ -4.1114, -18.2395,  -3.1101,   4.6724,  14.9533,  -0.5887,  -3.9349,\n",
       "          -8.2939, -13.5061,   0.2360],\n",
       "        [  4.6879, -10.6697, -13.4078,   2.2581,   9.5738,   2.6303, -12.7700,\n",
       "          -7.5225, -19.4016,  -2.7381],\n",
       "        [ -6.6830, -11.8551, -17.8105,  15.6536,   5.1534,   6.3852, -15.7121,\n",
       "         -10.2146,  -3.6838,  -6.8510],\n",
       "        [ -5.3000, -12.3611,   4.4223,   1.5886,   8.7482,   7.1677, -16.3309,\n",
       "          -3.8679, -17.9718,  -8.1005],\n",
       "        [  1.6560, -13.3679,   1.8834,   6.3848,   7.7889,   8.4087, -13.3304,\n",
       "          -5.0840, -26.0995,   3.9775],\n",
       "        [ -5.6628,  -6.4915,  -0.5647,   8.6566,  11.7627,  10.1090,  -9.6160,\n",
       "           2.0335,  -5.2181,  -8.7222],\n",
       "        [  3.4561, -19.2844,  -2.1494,   4.9003,  10.5306,   7.7962, -16.6741,\n",
       "          -2.5193,  -8.0417,  -8.9311],\n",
       "        [  2.5707,   0.7076, -11.8850,   6.8337,   3.8715,   8.8140, -13.2304,\n",
       "           0.1539, -19.3631,   0.8217],\n",
       "        [  0.0927,  -7.1297,  -9.5113,  11.3567,  11.2014,  10.6417,  -8.0217,\n",
       "          -2.6275, -11.4022,   1.6786],\n",
       "        [  2.6127,  -8.5093,  -5.0037,   1.1571,  12.2024,  13.6933, -12.7904,\n",
       "          -2.6443, -15.4362,  -8.3606],\n",
       "        [  4.7045, -22.5954, -16.4569,  -0.1687,   5.3478,  14.7962, -24.5881,\n",
       "          10.8465, -22.6177,  -3.5915],\n",
       "        [ -7.3606, -18.6806,  -7.8864,   3.4943,   1.4032,   4.6095, -12.0196,\n",
       "          -1.5800, -15.8557,  -8.7607],\n",
       "        [  0.5951,  -7.0884, -13.3914,   7.0484,  14.5038,   8.0632,  -3.0670,\n",
       "           3.0843,  -6.9065,   8.5891],\n",
       "        [ -5.6802, -14.0209,   0.8551,  -1.6424,   7.3925,   7.9997, -12.0644,\n",
       "         -20.9478,  -3.7692, -13.1956],\n",
       "        [ -9.0441,  -8.1713,  -3.5427,   3.8815,   9.4395,   9.9911, -12.3610,\n",
       "           2.8656, -16.4610, -11.8757],\n",
       "        [ -0.0428, -12.0283, -15.7232,  17.1491,   4.4592,   3.5752, -20.8317,\n",
       "         -14.0967, -13.2426,  -6.1092],\n",
       "        [ -5.6929, -14.6667,  -4.7472,  -0.3834,  15.6042,  14.7754,   5.9099,\n",
       "           2.1806, -12.1842,  -6.8939],\n",
       "        [  5.8088,  -5.8203, -13.5604,   4.1121,   1.9583,  13.3549,  -8.1752,\n",
       "          -1.3954,  -3.5665,   0.3212],\n",
       "        [ -0.4172,  -8.2645,   9.8506,   6.1213,   6.8730,  12.1587,  -9.4127,\n",
       "          -6.0374, -15.4947,  -9.0248],\n",
       "        [  7.5680, -12.0470,   2.5862,  20.5333,   6.9031,   4.6063,  -1.2441,\n",
       "         -19.4205, -14.1317,  -3.9867],\n",
       "        [  0.4124, -14.1363, -10.1840,  10.8276,  11.8434,  -3.3125, -16.2593,\n",
       "         -13.9612,  -2.1410,   4.7401],\n",
       "        [ -4.5194, -21.1909, -16.2109,   0.6980,  13.1226,   7.8626, -19.9965,\n",
       "         -13.8779, -18.0904,  -9.5798],\n",
       "        [  6.9093, -14.7586, -17.2362,  12.7872,  11.0356,  10.6633, -19.6209,\n",
       "          -4.9341, -12.6049, -16.3817],\n",
       "        [ -4.4951, -12.4997,   2.9503,   7.9761,  10.2427,  13.3823, -14.3947,\n",
       "           3.6414, -12.1932,   5.6023],\n",
       "        [  0.3937,  -5.7263,   1.4290,   7.0478,  12.9985,   3.3474, -14.7136,\n",
       "          -1.0192, -12.8108,  -5.9527],\n",
       "        [ -0.7050,  -8.3754,  -3.9948,   8.2880,   3.5716,   7.6259,  -3.4963,\n",
       "          -4.4408, -11.4785,  -3.3015],\n",
       "        [  2.1924, -15.7076,   5.6002,   1.9405,  11.5325,  12.9731,  -3.6039,\n",
       "          -8.4271,  -9.0522,   2.3505],\n",
       "        [  0.9811, -14.7969, -10.2548,  -3.0901,  12.6758,  15.8789, -12.0837,\n",
       "          -5.6404, -15.4347,   0.5095],\n",
       "        [  4.5554, -11.1317,  -9.5192,  17.9627,   4.8332,   3.8979,  -1.7709,\n",
       "         -12.0392, -16.6454,   3.1740],\n",
       "        [-10.8808, -18.9661, -17.8384,  -5.2533,   6.7052,   5.8937, -14.9781,\n",
       "          -4.6488, -19.6141,  -3.8821],\n",
       "        [  5.2275, -18.5322,  -3.7819,  -3.2833,  -1.5024,  11.2852, -25.5211,\n",
       "           8.9153, -17.8175,  -7.2751],\n",
       "        [  2.2952, -11.0099, -10.8837,  -0.7650,   6.0721,  10.8458, -20.7327,\n",
       "           9.4184, -15.5927,  -6.0494],\n",
       "        [  1.8947, -10.8078,   0.9111,   1.5016,  12.4433,  12.6050,  -0.1658,\n",
       "           0.6674, -19.4050,  -3.0533],\n",
       "        [  3.6204,  -7.7499,  -2.2766,  -3.7641,  16.6543,  14.6807, -12.5480,\n",
       "          -3.7490, -18.0315,  -0.9786],\n",
       "        [  6.0114, -23.4756,  -7.7937,   5.0235,  -3.2608,  19.4837, -23.3162,\n",
       "           4.9826, -21.6595,  -2.3598],\n",
       "        [  3.0258,  -6.4494, -16.8943,   8.2935,   9.6298,  12.9346, -17.0449,\n",
       "           2.5079, -18.9807,  -2.0111],\n",
       "        [  6.9613, -11.5540,  -6.0956,  10.3507,  13.6650,   8.7626, -15.8399,\n",
       "          -6.3310,  -8.0388,   0.6281],\n",
       "        [ 11.4803,  -8.9852,  -9.7371,  11.3347,   1.9126,  14.3977, -10.9899,\n",
       "           2.0860, -25.8734,  -8.2361],\n",
       "        [  4.0357, -12.0148,  -3.9400,   5.9824,  15.9003,  12.1790,  -7.3325,\n",
       "          -6.2917, -10.9192,  -8.1877],\n",
       "        [ -3.2991,  -8.8361,  -1.6328,  -0.5676,  13.3732,  17.3320,  -7.2265,\n",
       "          -6.3310, -18.9561,   7.2355],\n",
       "        [  8.6420, -21.3509,  -9.9856,   0.1037,  10.9209,  -3.7196, -17.6055,\n",
       "          -6.6311, -11.6343,  -5.5402],\n",
       "        [ -0.6602, -10.2603, -10.2159,   3.0630,   4.5596,   8.7553,  -2.8885,\n",
       "          -1.1678, -24.2917,   1.6311],\n",
       "        [ -0.2946, -13.6457,  -8.8136,  10.4856,   0.8889,  11.1437, -14.2824,\n",
       "          -9.6747, -13.7418,   3.6714],\n",
       "        [  4.3027, -15.6225,   1.9902,   7.3863,   0.3702,  10.9892,  -3.8530,\n",
       "          -7.6347, -12.9647,  -1.2860],\n",
       "        [  0.3701, -15.1888,  -0.6865,   1.2239,  10.5267,  14.9723,  -0.3007,\n",
       "          -8.1069,  -9.9865,  12.4367],\n",
       "        [ -0.5652, -10.9045, -11.3165,  -0.1435,   7.0083,   2.4159,  -9.2380,\n",
       "          -0.0675, -12.0969,   0.3449],\n",
       "        [  5.1825, -10.9507,   3.1568,   5.5348,   5.9330,  10.9736, -11.2392,\n",
       "           2.1946, -16.5807,  -1.1744]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: \n",
    "\n",
    "Implement a function softmax that performs the softmax calculation and returns probability distributions for each example in the batch. Note that you'll need to pay attention to the shapes when doing this. \n",
    "\n",
    "If you have a tensor a with shape (64, 10) and a tensor b with shape (64,), doing a/b will give you an error because PyTorch will try to do the division across the columns (called broadcasting) but you'll get a size mismatch. \n",
    "\n",
    "The way to think about this is for each of the 64 examples, you only want to divide by one value, the sum in the denominator. So you need b to have a shape of (64, 1). This way PyTorch will divide the 10 values in each row of a by the one value in each row of b. \n",
    "\n",
    "Pay attention to how you take the sum as well. \n",
    "\n",
    "You'll need to define the dim keyword in torch.sum. \n",
    "\n",
    "Setting dim=0 takes the sum across the rows while dim=1 takes the sum across the columns.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3687e+01, 1.0740e-07, 1.6598e-04, 2.4528e+04, 9.2827e+00, 7.4083e+06,\n",
       "         3.3757e-03, 3.6675e+01, 8.2854e-09, 8.4612e-01],\n",
       "        [3.2073e-02, 1.3713e-03, 2.0513e+00, 1.4752e+01, 1.3412e+04, 1.5886e+04,\n",
       "         3.0837e-02, 3.7833e-01, 2.7278e-11, 3.3589e+02],\n",
       "        [9.6523e+01, 2.3636e-05, 1.7606e-06, 2.0285e+00, 2.7982e+04, 4.3780e+02,\n",
       "         5.6737e-03, 3.6439e-03, 7.6801e-11, 2.8653e+00],\n",
       "        [7.0580e-01, 4.5696e-01, 2.7385e-01, 4.5219e-02, 2.7132e+08, 3.0130e+01,\n",
       "         8.2258e-03, 7.4598e+03, 8.1301e-09, 1.6536e-02],\n",
       "        [6.1169e+01, 8.0700e-08, 5.7172e-01, 3.6524e+01, 8.0102e+01, 1.1489e+02,\n",
       "         4.7088e-09, 1.6054e-03, 1.1398e-11, 1.0775e-01],\n",
       "        [3.2603e-01, 4.4040e+00, 5.4915e-02, 3.8394e+02, 6.8030e+05, 1.6933e+03,\n",
       "         1.5115e-08, 2.4700e-04, 1.2336e-08, 1.9591e-01],\n",
       "        [4.6098e-01, 1.1106e-09, 7.4345e-07, 1.2571e+03, 5.4237e+01, 8.0033e+03,\n",
       "         1.1316e-01, 5.3685e+00, 1.3238e-07, 3.8942e-04],\n",
       "        [2.2469e-04, 2.4342e-05, 1.4719e-02, 4.7227e+00, 2.5808e+07, 1.8236e-01,\n",
       "         9.8276e-05, 5.8783e-04, 8.3861e-08, 6.7736e-01],\n",
       "        [1.2444e+02, 4.0611e-05, 3.4555e-06, 1.5855e+04, 2.7328e+00, 3.0538e+02,\n",
       "         6.3190e-09, 1.7371e+00, 8.8805e-08, 3.9046e-04],\n",
       "        [3.1380e+01, 1.8972e-07, 1.5971e+01, 2.5275e+01, 5.4348e+03, 1.1761e+04,\n",
       "         4.3225e-04, 8.7341e-04, 4.9773e-07, 1.9537e-02],\n",
       "        [1.5129e-02, 7.1366e-07, 4.0166e+02, 3.5842e+01, 6.0462e+02, 1.7622e+04,\n",
       "         1.0526e-08, 7.3097e-04, 2.6559e-08, 2.8266e-06],\n",
       "        [6.3762e-02, 3.1697e-08, 6.3622e+00, 9.9144e+01, 7.1853e+03, 5.8199e+02,\n",
       "         7.2849e-07, 2.8821e-02, 3.4435e-03, 1.1375e+00],\n",
       "        [1.7441e+01, 6.3239e-07, 2.4675e-07, 6.3008e+02, 2.7588e+02, 7.3298e+01,\n",
       "         9.4257e-05, 8.7641e-01, 4.0020e-06, 9.5141e-03],\n",
       "        [8.4991e-05, 1.1054e-09, 1.5105e-04, 2.0189e+00, 1.0354e+08, 7.0987e+06,\n",
       "         2.6942e+02, 1.2018e+01, 3.3717e-08, 5.8622e-04],\n",
       "        [2.6952e-04, 3.4118e-07, 2.4617e-02, 5.9862e+02, 1.1302e+07, 1.0429e+09,\n",
       "         9.6547e-02, 7.7162e-02, 1.0073e-04, 1.8401e+01],\n",
       "        [2.4861e+02, 2.1466e-07, 1.1734e-02, 2.4184e+03, 7.1255e+05, 2.1577e+06,\n",
       "         4.5319e-03, 1.4586e+00, 1.2690e-03, 6.3838e+01],\n",
       "        [1.4214e-03, 5.2345e-07, 9.2965e-05, 3.6315e+00, 9.4514e+00, 1.8595e+04,\n",
       "         1.6716e+00, 7.7308e+00, 1.1828e-03, 2.3036e-01],\n",
       "        [1.6385e-02, 1.1986e-08, 4.4597e-02, 1.0695e+02, 3.1199e+06, 5.5506e-01,\n",
       "         1.9547e-02, 2.5005e-04, 1.3627e-06, 1.2661e+00],\n",
       "        [1.0863e+02, 2.3238e-05, 1.5034e-06, 9.5646e+00, 1.4383e+04, 1.3877e+01,\n",
       "         2.8448e-06, 5.4079e-04, 3.7495e-09, 6.4692e-02],\n",
       "        [1.2521e-03, 7.1025e-06, 1.8407e-08, 6.2842e+06, 1.7301e+02, 5.9300e+02,\n",
       "         1.5008e-07, 3.6632e-05, 2.5128e-02, 1.0584e-03],\n",
       "        [4.9915e-03, 4.2821e-06, 8.3288e+01, 4.8967e+00, 6.2993e+03, 1.2969e+03,\n",
       "         8.0830e-08, 2.0903e-02, 1.5665e-08, 3.0339e-04],\n",
       "        [5.2382e+00, 1.5645e-06, 6.5756e+00, 5.9276e+02, 2.4136e+03, 4.4857e+03,\n",
       "         1.6243e-06, 6.1953e-03, 4.6252e-12, 5.3381e+01],\n",
       "        [3.4727e-03, 1.5163e-03, 5.6854e-01, 5.7479e+03, 1.2838e+05, 2.4562e+04,\n",
       "         6.6653e-05, 7.6407e+00, 5.4177e-03, 1.6293e-04],\n",
       "        [3.1693e+01, 4.2158e-09, 1.1656e-01, 1.3433e+02, 3.7443e+04, 2.4314e+03,\n",
       "         5.7349e-08, 8.0518e-02, 3.2177e-04, 1.3221e-04],\n",
       "        [1.3075e+01, 2.0290e+00, 6.8933e-06, 9.2859e+02, 4.8016e+01, 6.7276e+03,\n",
       "         1.7952e-06, 1.1663e+00, 3.8967e-09, 2.2743e+00],\n",
       "        [1.0972e+00, 8.0098e-04, 7.4012e-05, 8.5535e+04, 7.3232e+04, 4.1845e+04,\n",
       "         3.2827e-04, 7.2257e-02, 1.1170e-05, 5.3579e+00],\n",
       "        [1.3635e+01, 2.0158e-04, 6.7129e-03, 3.1808e+00, 1.9926e+05, 8.8495e+05,\n",
       "         2.7874e-06, 7.1057e-02, 1.9777e-07, 2.3391e-04],\n",
       "        [1.1044e+02, 1.5379e-10, 7.1261e-08, 8.4473e-01, 2.1014e+02, 2.6664e+06,\n",
       "         2.0967e-11, 5.1356e+04, 1.5040e-10, 2.7558e-02],\n",
       "        [6.3582e-04, 7.7109e-09, 3.7580e-04, 3.2927e+01, 4.0682e+00, 1.0044e+02,\n",
       "         6.0251e-06, 2.0597e-01, 1.3001e-07, 1.5677e-04],\n",
       "        [1.8132e+00, 8.3475e-04, 1.5282e-06, 1.1510e+03, 1.9902e+06, 3.1754e+03,\n",
       "         4.6560e-02, 2.1852e+01, 1.0013e-03, 5.3725e+03],\n",
       "        [3.4128e-03, 8.1437e-07, 2.3516e+00, 1.9352e-01, 1.6238e+03, 2.9801e+03,\n",
       "         5.7610e-06, 7.9892e-10, 2.3070e-02, 1.8587e-06],\n",
       "        [1.1809e-04, 2.8265e-04, 2.8936e-02, 4.8497e+01, 1.2576e+04, 2.1831e+04,\n",
       "         4.2824e-06, 1.7559e+01, 7.0971e-08, 6.9576e-06],\n",
       "        [9.5809e-01, 5.9727e-06, 1.4842e-07, 2.8040e+07, 8.6419e+01, 3.5703e+01,\n",
       "         8.9724e-10, 7.5485e-07, 1.7735e-06, 2.2223e-03],\n",
       "        [3.3699e-03, 4.2692e-07, 8.6764e-03, 6.8155e-01, 5.9819e+06, 2.6114e+06,\n",
       "         3.6869e+02, 8.8515e+00, 5.1106e-06, 1.0139e-03],\n",
       "        [3.3321e+02, 2.9667e-03, 1.2906e-06, 6.1074e+01, 7.0876e+00, 6.3087e+05,\n",
       "         2.8154e-04, 2.4773e-01, 2.8254e-02, 1.3787e+00],\n",
       "        [6.5891e-01, 2.5749e-04, 1.8969e+04, 4.5546e+02, 9.6583e+02, 1.9074e+05,\n",
       "         8.1681e-05, 2.3879e-03, 1.8652e-07, 1.2039e-04],\n",
       "        [1.9353e+03, 5.8624e-06, 1.3279e+01, 8.2698e+08, 9.9532e+02, 1.0011e+02,\n",
       "         2.8819e-01, 3.6794e-09, 7.2895e-07, 1.8561e-02],\n",
       "        [1.5105e+00, 7.2557e-07, 3.7769e-05, 5.0391e+04, 1.3917e+05, 3.6425e-02,\n",
       "         8.6832e-08, 8.6444e-07, 1.1754e-01, 1.1445e+02],\n",
       "        [1.0896e-02, 6.2649e-10, 9.1134e-08, 2.0096e+00, 5.0013e+05, 2.5982e+03,\n",
       "         2.0683e-09, 9.3950e-07, 1.3914e-08, 6.9107e-05],\n",
       "        [1.0016e+03, 3.8942e-07, 3.2689e-08, 3.5761e+05, 6.2046e+04, 4.2758e+04,\n",
       "         3.0112e-09, 7.1970e-03, 3.3557e-06, 7.6826e-08],\n",
       "        [1.1164e-02, 3.7278e-06, 1.9111e+01, 2.9106e+03, 2.8076e+04, 6.4841e+05,\n",
       "         5.6036e-07, 3.8144e+01, 5.0647e-06, 2.7105e+02],\n",
       "        [1.4825e+00, 3.2590e-03, 4.1745e+00, 1.1503e+03, 4.4176e+05, 2.8428e+01,\n",
       "         4.0733e-07, 3.6087e-01, 2.7310e-06, 2.5989e-03],\n",
       "        [4.9412e-01, 2.3048e-04, 1.8411e-02, 3.9757e+03, 3.5575e+01, 2.0506e+03,\n",
       "         3.0308e-02, 1.1787e-02, 1.0350e-05, 3.6827e-02],\n",
       "        [8.9570e+00, 1.5075e-07, 2.7049e+02, 6.9621e+00, 1.0198e+05, 4.3067e+05,\n",
       "         2.7218e-02, 2.1886e-04, 1.1713e-04, 1.0491e+01],\n",
       "        [2.6674e+00, 3.7481e-07, 3.5188e-05, 4.5497e-02, 3.1992e+05, 7.8730e+06,\n",
       "         5.6509e-06, 3.5514e-03, 1.9807e-07, 1.6644e+00],\n",
       "        [9.5148e+01, 1.4641e-05, 7.3425e-05, 6.3255e+07, 1.2561e+02, 4.9299e+01,\n",
       "         1.7018e-01, 5.9080e-06, 5.9017e-08, 2.3904e+01],\n",
       "        [1.8817e-05, 5.7959e-09, 1.7900e-08, 5.2302e-03, 8.1666e+02, 3.6275e+02,\n",
       "         3.1267e-07, 9.5728e-03, 3.0320e-09, 2.0607e-02],\n",
       "        [1.8632e+02, 8.9448e-09, 2.2780e-02, 3.7502e-02, 2.2259e-01, 7.9638e+04,\n",
       "         8.2472e-12, 7.4452e+03, 1.8278e-08, 6.9255e-04],\n",
       "        [9.9263e+00, 1.6537e-05, 1.8762e-05, 4.6534e-01, 4.3357e+02, 5.1316e+04,\n",
       "         9.9060e-10, 1.2313e+04, 1.6911e-07, 2.3593e-03],\n",
       "        [6.6503e+00, 2.0241e-05, 2.4871e+00, 4.4891e+00, 2.5355e+05, 2.9803e+05,\n",
       "         8.4723e-01, 1.9492e+00, 3.7368e-09, 4.7203e-02],\n",
       "        [3.7353e+01, 4.3077e-04, 1.0263e-01, 2.3188e-02, 1.7095e+07, 2.3754e+06,\n",
       "         3.5520e-06, 2.3542e-02, 1.4758e-08, 3.7582e-01],\n",
       "        [4.0806e+02, 6.3780e-11, 4.1232e-04, 1.5194e+02, 3.8357e-02, 2.8951e+08,\n",
       "         7.4797e-11, 1.4585e+02, 3.9212e-10, 9.4438e-02],\n",
       "        [2.0611e+01, 1.5815e-03, 4.6014e-08, 3.9976e+03, 1.5211e+04, 4.1439e+05,\n",
       "         3.9583e-08, 1.2280e+01, 5.7120e-09, 1.3384e-01],\n",
       "        [1.0550e+03, 9.5980e-06, 2.2527e-03, 3.1280e+04, 8.6025e+05, 6.3907e+03,\n",
       "         1.3208e-07, 1.7803e-03, 3.2271e-04, 1.8741e+00],\n",
       "        [9.6791e+04, 1.2525e-04, 5.9052e-05, 8.3677e+04, 6.7704e+00, 1.7899e+06,\n",
       "         1.6871e-05, 8.0523e+00, 5.7986e-12, 2.6491e-04],\n",
       "        [5.6584e+01, 6.0537e-06, 1.9449e-02, 3.9640e+02, 8.0431e+06, 1.9466e+05,\n",
       "         6.5391e-04, 1.8516e-03, 1.8108e-05, 2.7806e-04],\n",
       "        [3.6915e-02, 1.4538e-04, 1.9539e-01, 5.6687e-01, 6.4253e+05, 3.3667e+07,\n",
       "         7.2709e-04, 1.7802e-03, 5.8541e-09, 1.3878e+03],\n",
       "        [5.6646e+03, 5.3388e-10, 4.6060e-05, 1.1092e+00, 5.5320e+04, 2.4243e-02,\n",
       "         2.2596e-08, 1.3187e-03, 8.8574e-06, 3.9257e-03],\n",
       "        [5.1676e-01, 3.4996e-05, 3.6585e-05, 2.1391e+01, 9.5541e+01, 6.3444e+03,\n",
       "         5.5659e-02, 3.1105e-01, 2.8200e-11, 5.1094e+00],\n",
       "        [7.4483e-01, 1.1851e-06, 1.4869e-04, 3.5795e+04, 2.4325e+00, 6.9128e+04,\n",
       "         6.2695e-07, 6.2853e-05, 1.0765e-06, 3.9309e+01],\n",
       "        [7.3901e+01, 1.6415e-07, 7.3173e+00, 1.6137e+03, 1.4481e+00, 5.9229e+04,\n",
       "         2.1217e-02, 4.8338e-04, 2.3416e-06, 2.7639e-01],\n",
       "        [1.4479e+00, 2.5327e-07, 5.0335e-01, 3.4004e+00, 3.7298e+04, 3.1797e+06,\n",
       "         7.4029e-01, 3.0145e-04, 4.6016e-05, 2.5187e+05],\n",
       "        [5.6827e-01, 1.8375e-05, 1.2170e-05, 8.6636e-01, 1.1058e+03, 1.1200e+01,\n",
       "         9.7268e-05, 9.3472e-01, 5.5765e-06, 1.4118e+00],\n",
       "        [1.7812e+02, 1.7546e-05, 2.3494e+01, 2.5335e+02, 3.7730e+02, 5.8315e+04,\n",
       "         1.3148e-05, 8.9762e+00, 6.2962e-08, 3.0901e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = torch.exp(out)\n",
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2786812928.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = torch.sum(torch.exp(out))\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.4330e+06, 2.9651e+04, 2.8521e+04, 2.7133e+08, 2.9337e+02, 6.8239e+05,\n",
       "        9.3205e+03, 2.5808e+07, 1.6290e+04, 1.7269e+04, 1.8664e+04, 7.8740e+03,\n",
       "        9.9759e+02, 1.1064e+08, 1.0542e+09, 2.8730e+06, 1.8618e+04, 3.1200e+06,\n",
       "        1.4515e+04, 6.2850e+06, 7.6844e+03, 7.5573e+03, 1.5869e+05, 4.0040e+04,\n",
       "        7.7227e+03, 2.0062e+05, 1.0842e+06, 2.7181e+06, 1.3764e+02, 2.0000e+06,\n",
       "        4.6064e+03, 3.4473e+04, 2.8040e+07, 8.5937e+06, 6.3127e+05, 2.1113e+05,\n",
       "        8.2698e+08, 1.8967e+05, 5.0273e+05, 4.6342e+05, 6.7972e+05, 4.4294e+05,\n",
       "        6.0625e+03, 5.3295e+05, 8.1929e+06, 6.3255e+07, 1.1794e+03, 8.7270e+04,\n",
       "        6.4073e+04, 5.5160e+05, 1.9470e+07, 2.8951e+08, 4.3363e+05, 8.9898e+05,\n",
       "        1.9704e+06, 8.2382e+06, 3.4311e+07, 6.0986e+04, 6.4673e+03, 1.0497e+05,\n",
       "        6.0926e+04, 3.4689e+06, 1.1208e+03, 5.9156e+04])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = torch.sum(torch.exp(out),dim = 1)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.4330e+06],\n",
       "        [2.9651e+04],\n",
       "        [2.8521e+04],\n",
       "        [2.7133e+08],\n",
       "        [2.9337e+02],\n",
       "        [6.8239e+05],\n",
       "        [9.3205e+03],\n",
       "        [2.5808e+07],\n",
       "        [1.6290e+04],\n",
       "        [1.7269e+04],\n",
       "        [1.8664e+04],\n",
       "        [7.8740e+03],\n",
       "        [9.9759e+02],\n",
       "        [1.1064e+08],\n",
       "        [1.0542e+09],\n",
       "        [2.8730e+06],\n",
       "        [1.8618e+04],\n",
       "        [3.1200e+06],\n",
       "        [1.4515e+04],\n",
       "        [6.2850e+06],\n",
       "        [7.6844e+03],\n",
       "        [7.5573e+03],\n",
       "        [1.5869e+05],\n",
       "        [4.0040e+04],\n",
       "        [7.7227e+03],\n",
       "        [2.0062e+05],\n",
       "        [1.0842e+06],\n",
       "        [2.7181e+06],\n",
       "        [1.3764e+02],\n",
       "        [2.0000e+06],\n",
       "        [4.6064e+03],\n",
       "        [3.4473e+04],\n",
       "        [2.8040e+07],\n",
       "        [8.5937e+06],\n",
       "        [6.3127e+05],\n",
       "        [2.1113e+05],\n",
       "        [8.2698e+08],\n",
       "        [1.8967e+05],\n",
       "        [5.0273e+05],\n",
       "        [4.6342e+05],\n",
       "        [6.7972e+05],\n",
       "        [4.4294e+05],\n",
       "        [6.0625e+03],\n",
       "        [5.3295e+05],\n",
       "        [8.1929e+06],\n",
       "        [6.3255e+07],\n",
       "        [1.1794e+03],\n",
       "        [8.7270e+04],\n",
       "        [6.4073e+04],\n",
       "        [5.5160e+05],\n",
       "        [1.9470e+07],\n",
       "        [2.8951e+08],\n",
       "        [4.3363e+05],\n",
       "        [8.9898e+05],\n",
       "        [1.9704e+06],\n",
       "        [8.2382e+06],\n",
       "        [3.4311e+07],\n",
       "        [6.0986e+04],\n",
       "        [6.4673e+03],\n",
       "        [1.0497e+05],\n",
       "        [6.0926e+04],\n",
       "        [3.4689e+06],\n",
       "        [1.1208e+03],\n",
       "        [5.9156e+04]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = d1.view(-1,1)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x),dim = -1).view(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1259e-05, 1.4450e-14, 2.2330e-11, 3.2999e-03, 1.2488e-06, 9.9668e-01,\n",
       "         4.5415e-10, 4.9341e-06, 1.1147e-15, 1.1383e-07],\n",
       "        [1.0817e-06, 4.6247e-08, 6.9180e-05, 4.9750e-04, 4.5233e-01, 5.3576e-01,\n",
       "         1.0400e-06, 1.2759e-05, 9.1995e-16, 1.1328e-02],\n",
       "        [3.3842e-03, 8.2870e-10, 6.1730e-11, 7.1122e-05, 9.8109e-01, 1.5350e-02,\n",
       "         1.9893e-07, 1.2776e-07, 2.6928e-15, 1.0046e-04],\n",
       "        [2.6012e-09, 1.6841e-09, 1.0093e-09, 1.6665e-10, 9.9997e-01, 1.1104e-07,\n",
       "         3.0316e-11, 2.7493e-05, 2.9964e-17, 6.0942e-11],\n",
       "        [2.0851e-01, 2.7508e-10, 1.9488e-03, 1.2450e-01, 2.7304e-01, 3.9163e-01,\n",
       "         1.6051e-11, 5.4723e-06, 3.8852e-14, 3.6730e-04],\n",
       "        [4.7778e-07, 6.4539e-06, 8.0476e-08, 5.6264e-04, 9.9695e-01, 2.4815e-03,\n",
       "         2.2150e-14, 3.6197e-10, 1.8078e-14, 2.8710e-07],\n",
       "        [4.9459e-05, 1.1916e-13, 7.9765e-11, 1.3487e-01, 5.8191e-03, 8.5867e-01,\n",
       "         1.2140e-05, 5.7598e-04, 1.4203e-11, 4.1781e-08],\n",
       "        [8.7060e-12, 9.4316e-13, 5.7033e-10, 1.8299e-07, 1.0000e+00, 7.0658e-09,\n",
       "         3.8079e-12, 2.2777e-11, 3.2494e-15, 2.6246e-08],\n",
       "        [7.6392e-03, 2.4931e-09, 2.1213e-10, 9.7334e-01, 1.6776e-04, 1.8747e-02,\n",
       "         3.8792e-13, 1.0663e-04, 5.4516e-12, 2.3970e-08],\n",
       "        [1.8172e-03, 1.0986e-11, 9.2485e-04, 1.4637e-03, 3.1472e-01, 6.8107e-01,\n",
       "         2.5031e-08, 5.0578e-08, 2.8823e-11, 1.1314e-06],\n",
       "        [8.1059e-07, 3.8238e-11, 2.1521e-02, 1.9204e-03, 3.2396e-02, 9.4416e-01,\n",
       "         5.6397e-13, 3.9165e-08, 1.4230e-12, 1.5145e-10],\n",
       "        [8.0978e-06, 4.0256e-12, 8.0800e-04, 1.2591e-02, 9.1253e-01, 7.3913e-02,\n",
       "         9.2518e-11, 3.6602e-06, 4.3732e-07, 1.4446e-04],\n",
       "        [1.7483e-02, 6.3392e-10, 2.4734e-10, 6.3160e-01, 2.7655e-01, 7.3475e-02,\n",
       "         9.4485e-08, 8.7853e-04, 4.0117e-09, 9.5371e-06],\n",
       "        [7.6817e-13, 9.9908e-18, 1.3652e-12, 1.8247e-08, 9.3584e-01, 6.4160e-02,\n",
       "         2.4351e-06, 1.0862e-07, 3.0474e-16, 5.2983e-12],\n",
       "        [2.5567e-13, 3.2365e-16, 2.3351e-11, 5.6785e-07, 1.0721e-02, 9.8928e-01,\n",
       "         9.1584e-11, 7.3195e-11, 9.5557e-14, 1.7455e-08],\n",
       "        [8.6534e-05, 7.4719e-14, 4.0844e-09, 8.4180e-04, 2.4802e-01, 7.5103e-01,\n",
       "         1.5774e-09, 5.0771e-07, 4.4171e-10, 2.2220e-05],\n",
       "        [7.6342e-08, 2.8115e-11, 4.9933e-09, 1.9505e-04, 5.0765e-04, 9.9878e-01,\n",
       "         8.9786e-05, 4.1523e-04, 6.3527e-08, 1.2373e-05],\n",
       "        [5.2515e-09, 3.8417e-15, 1.4294e-08, 3.4280e-05, 9.9997e-01, 1.7790e-07,\n",
       "         6.2651e-09, 8.0143e-11, 4.3675e-13, 4.0581e-07],\n",
       "        [7.4840e-03, 1.6009e-09, 1.0358e-10, 6.5895e-04, 9.9090e-01, 9.5608e-04,\n",
       "         1.9599e-10, 3.7257e-08, 2.5832e-13, 4.4569e-06],\n",
       "        [1.9922e-10, 1.1301e-12, 2.9288e-15, 9.9988e-01, 2.7528e-05, 9.4352e-05,\n",
       "         2.3879e-14, 5.8284e-12, 3.9981e-09, 1.6841e-10],\n",
       "        [6.4957e-07, 5.5724e-10, 1.0839e-02, 6.3722e-04, 8.1976e-01, 1.6876e-01,\n",
       "         1.0519e-11, 2.7202e-06, 2.0386e-12, 3.9481e-08],\n",
       "        [6.9313e-04, 2.0702e-10, 8.7011e-04, 7.8435e-02, 3.1937e-01, 5.9357e-01,\n",
       "         2.1493e-10, 8.1978e-07, 6.1202e-16, 7.0636e-03],\n",
       "        [2.1883e-08, 9.5547e-09, 3.5826e-06, 3.6220e-02, 8.0895e-01, 1.5478e-01,\n",
       "         4.2000e-10, 4.8147e-05, 3.4139e-08, 1.0267e-09],\n",
       "        [7.9153e-04, 1.0529e-13, 2.9110e-06, 3.3550e-03, 9.3512e-01, 6.0724e-02,\n",
       "         1.4323e-12, 2.0109e-06, 8.0363e-09, 3.3020e-09],\n",
       "        [1.6931e-03, 2.6274e-04, 8.9260e-10, 1.2024e-01, 6.2174e-03, 8.7114e-01,\n",
       "         2.3245e-10, 1.5102e-04, 5.0457e-13, 2.9449e-04],\n",
       "        [5.4690e-06, 3.9926e-09, 3.6892e-10, 4.2636e-01, 3.6503e-01, 2.0858e-01,\n",
       "         1.6363e-09, 3.6017e-07, 5.5680e-11, 2.6707e-05],\n",
       "        [1.2576e-05, 1.8592e-10, 6.1914e-09, 2.9337e-06, 1.8378e-01, 8.1620e-01,\n",
       "         2.5709e-12, 6.5537e-08, 1.8241e-13, 2.1573e-10],\n",
       "        [4.0632e-05, 5.6579e-17, 2.6217e-14, 3.1078e-07, 7.7313e-05, 9.8099e-01,\n",
       "         7.7138e-18, 1.8894e-02, 5.5332e-17, 1.0139e-08],\n",
       "        [4.6195e-06, 5.6023e-11, 2.7304e-06, 2.3923e-01, 2.9557e-02, 7.2971e-01,\n",
       "         4.3775e-08, 1.4964e-03, 9.4456e-10, 1.1390e-06],\n",
       "        [9.0659e-07, 4.1738e-10, 7.6412e-13, 5.7550e-04, 9.9514e-01, 1.5877e-03,\n",
       "         2.3281e-08, 1.0926e-05, 5.0065e-10, 2.6863e-03],\n",
       "        [7.4089e-07, 1.7679e-10, 5.1050e-04, 4.2010e-05, 3.5251e-01, 6.4694e-01,\n",
       "         1.2506e-09, 1.7344e-13, 5.0083e-06, 4.0351e-10],\n",
       "        [3.4255e-09, 8.1993e-09, 8.3937e-07, 1.4068e-03, 3.6480e-01, 6.3329e-01,\n",
       "         1.2422e-10, 5.0935e-04, 2.0587e-12, 2.0183e-10],\n",
       "        [3.4169e-08, 2.1300e-13, 5.2933e-15, 1.0000e+00, 3.0820e-06, 1.2733e-06,\n",
       "         3.1998e-17, 2.6920e-14, 6.3248e-14, 7.9254e-11],\n",
       "        [3.9214e-10, 4.9678e-14, 1.0096e-09, 7.9309e-08, 6.9608e-01, 3.0387e-01,\n",
       "         4.2902e-05, 1.0300e-06, 5.9470e-13, 1.1798e-10],\n",
       "        [5.2784e-04, 4.6995e-09, 2.0444e-12, 9.6748e-05, 1.1227e-05, 9.9936e-01,\n",
       "         4.4599e-10, 3.9244e-07, 4.4757e-08, 2.1840e-06],\n",
       "        [3.1208e-06, 1.2196e-09, 8.9846e-02, 2.1572e-03, 4.5745e-03, 9.0342e-01,\n",
       "         3.8687e-10, 1.1310e-08, 8.8341e-13, 5.7021e-10],\n",
       "        [2.3402e-06, 7.0889e-15, 1.6057e-08, 1.0000e+00, 1.2036e-06, 1.2105e-07,\n",
       "         3.4848e-10, 4.4492e-18, 8.8146e-16, 2.2445e-11],\n",
       "        [7.9636e-06, 3.8254e-12, 1.9913e-10, 2.6567e-01, 7.3372e-01, 1.9204e-07,\n",
       "         4.5780e-13, 4.5575e-12, 6.1969e-07, 6.0341e-04],\n",
       "        [2.1674e-08, 1.2462e-15, 1.8128e-13, 3.9975e-06, 9.9483e-01, 5.1683e-03,\n",
       "         4.1142e-15, 1.8688e-12, 2.7677e-14, 1.3746e-10],\n",
       "        [2.1612e-03, 8.4033e-13, 7.0540e-14, 7.7169e-01, 1.3389e-01, 9.2266e-02,\n",
       "         6.4977e-15, 1.5530e-08, 7.2411e-12, 1.6578e-13],\n",
       "        [1.6424e-08, 5.4843e-12, 2.8116e-05, 4.2820e-03, 4.1306e-02, 9.5393e-01,\n",
       "         8.2440e-13, 5.6116e-05, 7.4511e-12, 3.9876e-04],\n",
       "        [3.3468e-06, 7.3576e-09, 9.4245e-06, 2.5969e-03, 9.9733e-01, 6.4180e-05,\n",
       "         9.1960e-13, 8.1471e-07, 6.1656e-12, 5.8673e-09],\n",
       "        [8.1505e-05, 3.8017e-08, 3.0368e-06, 6.5579e-01, 5.8680e-03, 3.3824e-01,\n",
       "         4.9993e-06, 1.9443e-06, 1.7072e-09, 6.0745e-06],\n",
       "        [1.6807e-05, 2.8287e-13, 5.0753e-04, 1.3064e-05, 1.9135e-01, 8.0810e-01,\n",
       "         5.1071e-08, 4.1066e-10, 2.1978e-10, 1.9685e-05],\n",
       "        [3.2557e-07, 4.5748e-14, 4.2950e-12, 5.5532e-09, 3.9049e-02, 9.6095e-01,\n",
       "         6.8974e-13, 4.3347e-10, 2.4176e-14, 2.0315e-07],\n",
       "        [1.5042e-06, 2.3146e-13, 1.1608e-12, 1.0000e+00, 1.9857e-06, 7.7936e-07,\n",
       "         2.6904e-09, 9.3399e-14, 9.3300e-16, 3.7790e-07],\n",
       "        [1.5954e-08, 4.9141e-12, 1.5177e-11, 4.4345e-06, 6.9241e-01, 3.0756e-01,\n",
       "         2.6510e-10, 8.1163e-06, 2.5707e-12, 1.7471e-05],\n",
       "        [2.1350e-03, 1.0250e-13, 2.6102e-07, 4.2973e-07, 2.5506e-06, 9.1255e-01,\n",
       "         9.4502e-17, 8.5313e-02, 2.0945e-13, 7.9357e-09],\n",
       "        [1.5492e-04, 2.5810e-10, 2.9282e-10, 7.2627e-06, 6.7668e-03, 8.0089e-01,\n",
       "         1.5460e-14, 1.9218e-01, 2.6393e-12, 3.6822e-08],\n",
       "        [1.2056e-05, 3.6696e-11, 4.5090e-06, 8.1383e-06, 4.5966e-01, 5.4031e-01,\n",
       "         1.5360e-06, 3.5338e-06, 6.7745e-15, 8.5576e-08],\n",
       "        [1.9185e-06, 2.2125e-11, 5.2711e-09, 1.1910e-09, 8.7800e-01, 1.2200e-01,\n",
       "         1.8243e-13, 1.2091e-09, 7.5797e-16, 1.9303e-08],\n",
       "        [1.4095e-06, 2.2030e-19, 1.4242e-12, 5.2480e-07, 1.3249e-10, 1.0000e+00,\n",
       "         2.5836e-19, 5.0377e-07, 1.3544e-18, 3.2620e-10],\n",
       "        [4.7531e-05, 3.6470e-09, 1.0611e-13, 9.2189e-03, 3.5079e-02, 9.5563e-01,\n",
       "         9.1282e-14, 2.8318e-05, 1.3172e-14, 3.0865e-07],\n",
       "        [1.1735e-03, 1.0677e-11, 2.5058e-09, 3.4795e-02, 9.5692e-01, 7.1088e-03,\n",
       "         1.4692e-13, 1.9803e-09, 3.5898e-10, 2.0846e-06],\n",
       "        [4.9123e-02, 6.3566e-11, 2.9970e-11, 4.2468e-02, 3.4361e-06, 9.0840e-01,\n",
       "         8.5623e-12, 4.0867e-06, 2.9429e-18, 1.3445e-10],\n",
       "        [6.8685e-06, 7.3483e-13, 2.3608e-09, 4.8118e-05, 9.7632e-01, 2.3629e-02,\n",
       "         7.9375e-11, 2.2475e-10, 2.1980e-12, 3.3753e-11],\n",
       "        [1.0759e-09, 4.2372e-12, 5.6946e-09, 1.6522e-08, 1.8727e-02, 9.8123e-01,\n",
       "         2.1191e-11, 5.1885e-11, 1.7062e-16, 4.0449e-05],\n",
       "        [9.2884e-02, 8.7541e-15, 7.5526e-10, 1.8188e-05, 9.0710e-01, 3.9751e-07,\n",
       "         3.7052e-13, 2.1623e-08, 1.4524e-10, 6.4371e-08],\n",
       "        [7.9904e-05, 5.4112e-09, 5.6569e-09, 3.3076e-03, 1.4773e-02, 9.8099e-01,\n",
       "         8.6062e-06, 4.8096e-05, 4.3604e-15, 7.9004e-04],\n",
       "        [7.0959e-06, 1.1290e-11, 1.4166e-09, 3.4102e-01, 2.3174e-05, 6.5858e-01,\n",
       "         5.9729e-12, 5.9879e-10, 1.0256e-11, 3.7449e-04],\n",
       "        [1.2130e-03, 2.6942e-12, 1.2010e-04, 2.6487e-02, 2.3768e-05, 9.7215e-01,\n",
       "         3.4824e-07, 7.9339e-09, 3.8434e-11, 4.5365e-06],\n",
       "        [4.1739e-07, 7.3011e-14, 1.4511e-07, 9.8025e-07, 1.0752e-02, 9.1664e-01,\n",
       "         2.1341e-07, 8.6900e-11, 1.3265e-11, 7.2609e-02],\n",
       "        [5.0702e-04, 1.6395e-08, 1.0858e-08, 7.7298e-04, 9.8663e-01, 9.9929e-03,\n",
       "         8.6784e-08, 8.3397e-04, 4.9755e-09, 1.2596e-03],\n",
       "        [3.0110e-03, 2.9661e-10, 3.9716e-04, 4.2828e-03, 6.3780e-03, 9.8577e-01,\n",
       "         2.2226e-10, 1.5174e-04, 1.0643e-12, 5.2237e-06]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = softmax(out)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "#shape should be 64,10, same as out\n",
    "print(probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "#sum of each column should be 1 i.e. normalized\n",
    "print(probabilities.sum(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
